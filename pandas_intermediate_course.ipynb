{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Pandas Techniques\n",
    "\n",
    "## Course Overview\n",
    "\n",
    "Building on the introduction, this notebook covers advanced Pandas techniques:\n",
    "- Advanced data manipulation\n",
    "- Time series analysis\n",
    "- Performance optimization\n",
    "- Advanced merging and joining\n",
    "- Data cleaning and preprocessing\n",
    "- Complex aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Creating complex DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar'],\n",
    "    'B': ['one', 'one', 'two', 'three', 'two', 'two'],\n",
    "    'C': np.random.randn(6),\n",
    "    'D': np.random.randn(6)\n",
    "})\n",
    "\n",
    "# Pivot table\n",
    "pivot = df.pivot_table(values='C', index='A', columns='B', aggfunc='mean')\n",
    "print(\"Pivot Table:\")\n",
    "print(pivot)\n",
    "\n",
    "# Melt transformation\n",
    "melted = df.melt(id_vars=['A', 'B'], value_vars=['C', 'D'])\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "print(melted.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate time series data\n",
    "dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "ts = pd.Series(np.random.randn(100), index=dates)\n",
    "\n",
    "# Resampling\n",
    "daily_mean = ts.resample('M').mean()\n",
    "print(\"Monthly Means:\")\n",
    "print(daily_mean)\n",
    "\n",
    "# Rolling window calculations\n",
    "rolling_mean = ts.rolling(window=7).mean()\n",
    "print(\"\\n7-Day Rolling Mean:\")\n",
    "print(rolling_mean.head())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Large dataset generation\n",
    "large_df = pd.DataFrame({\n",
    "    'category': np.random.choice(['A', 'B', 'C'], size=1000000),\n",
    "    'value': np.random.randn(1000000)\n",
    "})\n",
    "\n",
    "# Efficient groupby\n",
    "%time large_df.groupby('category')['value'].agg(['mean', 'sum'])\n",
    "\n",
    "# Using categoricals for memory efficiency\n",
    "large_df['category'] = large_df['category'].astype('category')\n",
    "%time large_df.groupby('category')['value'].agg(['mean', 'sum'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Merging and Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C', 'D'],\n",
    "    'value1': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['B', 'D', 'E', 'F'],\n",
    "    'value2': [20, 40, 50, 60]\n",
    "})\n",
    "\n",
    "# Different types of joins\n",
    "inner_join = pd.merge(df1, df2, on='key', how='inner')\n",
    "outer_join = pd.merge(df1, df2, on='key', how='outer')\n",
    "\n",
    "print(\"Inner Join:\")\n",
    "print(inner_join)\n",
    "\n",
    "print(\"\\nOuter Join:\")\n",
    "print(outer_join)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create DataFrame with missing and problematic data\n",
    "dirty_df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': ['a', 'b', 'c', None],\n",
    "    'C': ['2023-01-01', '2023-02-01', 'invalid', '2023-04-01']\n",
    "})\n",
    "\n",
    "# Handle missing values\n",
    "cleaned_df = dirty_df.copy()\n",
    "cleaned_df['A'].fillna(cleaned_df['A'].mean(), inplace=True)\n",
    "cleaned_df['B'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Convert to datetime with error handling\n",
    "cleaned_df['C'] = pd.to_datetime(cleaned_df['C'], errors='coerce')\n",
    "\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(cleaned_df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complex Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create multi-level DataFrame\n",
    "multi_df = pd.DataFrame({\n",
    "    'group1': ['A', 'A', 'B', 'B'],\n",
    "    'group2': ['X', 'Y', 'X', 'Y'],\n",
    "    'value1': [10, 20, 30, 40],\n",
    "    'value2': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "# Advanced groupby with multiple aggregations\n",
    "result = multi_df.groupby(['group1', 'group2']).agg({\n",
    "    'value1': ['sum', 'mean'],\n",
    "    'value2': ['max', 'min']\n",
    "})\n",
    "\n",
    "print(\"Multi-level Aggregation:\")\n",
    "print(result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Pandas Selection and Data Handling\n",
    "\n",
    "## Key Topics\n",
    "- Advanced indexing with `.loc` and `.iloc`\n",
    "- Comprehensive missing data strategies\n",
    "- Advanced grouping and pivoting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced Indexing: `.loc` vs `.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataFrame with labeled index\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 22],\n",
    "    'City': ['New York', 'SF', 'Chicago', 'Boston', 'LA']\n",
    "}, index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# .loc - Label-based indexing\n",
    "print(\"Selecting by label:\")\n",
    "print(df.loc['b'])  # Select row with label 'b'\n",
    "print(\"\\nMultiple label selection:\")\n",
    "print(df.loc[['a', 'c']])  # Select multiple rows\n",
    "\n",
    "# Conditional selection with .loc\n",
    "print(\"\\nConditional selection:\")\n",
    "print(df.loc[df['Age'] > 25, ['Name', 'City']])\n",
    "\n",
    "# .iloc - Integer-based indexing\n",
    "print(\"\\n.iloc indexing:\")\n",
    "print(df.iloc[1])  # Second row\n",
    "print(\"\\nSlice with .iloc:\")\n",
    "print(df.iloc[1:4, 0:2])  # Rows 1-3, first two columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create DataFrame with missing values\n",
    "missing_df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': ['apple', np.nan, 'cherry', 'date', np.nan]\n",
    "})\n",
    "\n",
    "# Detect missing values\n",
    "print(\"Missing value detection:\")\n",
    "print(missing_df.isna())  # Boolean mask of missing values\n",
    "print(\"\\nTotal missing values:\\n\", missing_df.isna().sum())\n",
    "\n",
    "# Handling missing values\n",
    "# Fill methods\n",
    "filled_mean = missing_df.fillna({\n",
    "    'A': missing_df['A'].mean(),\n",
    "    'B': 0,\n",
    "    'C': 'unknown'\n",
    "})\n",
    "\n",
    "# Advanced filling\n",
    "forward_filled = missing_df.fillna(method='ffill')  # Forward fill\n",
    "backward_filled = missing_df.fillna(method='bfill')  # Backward fill\n",
    "\n",
    "# Dropping missing values\n",
    "dropped = missing_df.dropna()  # Drop rows with ANY missing values\n",
    "dropped_all = missing_df.dropna(how='all')  # Drop only rows where ALL values are missing"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Grouping and Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create complex DataFrame for grouping\n",
    "sales_df = pd.DataFrame({\n",
    "    'Date': pd.date_range('2023-01-01', periods=12),\n",
    "    'Product': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'B', 'C', 'A'],\n",
    "    'Region': ['North', 'South', 'East', 'West', 'North', 'South', \n",
    "               'East', 'West', 'North', 'South', 'East', 'West'],\n",
    "    'Sales': np.random.randint(100, 1000, 12)\n",
    "})\n",
    "\n",
    "# Multi-level grouping\n",
    "grouped = sales_df.groupby(['Product', 'Region'])\n",
    "\n",
    "# Complex aggregation\n",
    "agg_result = grouped['Sales'].agg([\n",
    "    ('total_sales', 'sum'),\n",
    "    ('avg_sales', 'mean'),\n",
    "    ('max_sales', 'max')\n",
    "])\n",
    "print(\"Multi-level Aggregation:\")\n",
    "print(agg_result)\n",
    "\n",
    "# Pivot table\n",
    "pivot_table = sales_df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Product', \n",
    "    columns='Region', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(\"\\nPivot Table:\")\n",
    "print(pivot_table)\n",
    "\n",
    "# Advanced pivot with multiple aggregations\n",
    "multi_pivot = sales_df.pivot_table(\n",
    "    values='Sales', \n",
    "    index='Product', \n",
    "    columns='Region', \n",
    "    aggfunc=['mean', 'sum']\n",
    ")\n",
    "print(\"\\nMulti-aggregation Pivot:\")\n",
    "print(multi_pivot)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Techniques Summary\n",
    "\n",
    "Key advanced Pandas skills learned:\n",
    "- Complex data transformations\n",
    "- Time series manipulation\n",
    "- Performance optimization\n",
    "- Sophisticated merging\n",
    "- Data cleaning techniques\n",
    "- Multi-level aggregations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}